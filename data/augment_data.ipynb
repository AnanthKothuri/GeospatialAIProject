{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flood Event Data Processing\n",
        "\n",
        "This notebook processes storm event CSV files to extract and filter flooding events.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading initial data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_csv_files(data_dir: str) -> List[str]:\n",
        "    csv_files = []\n",
        "    data_path = Path(data_dir)\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        raise FileNotFoundError(f\"Directory {data_dir} does not exist\")\n",
        "    \n",
        "    for file in data_path.glob(\"*.csv\"):\n",
        "        csv_files.append(str(file))\n",
        "    \n",
        "    return sorted(csv_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_csv_file(file_path: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, low_memory=False)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")\n",
        "        return pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_flooding_events(df: pd.DataFrame, state: str = None) -> pd.DataFrame:\n",
        "    if df.empty or 'EVENT_TYPE' not in df.columns:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    flood_keywords = ['flood', 'flash flood', 'coastal flood', 'lakeshore flood', \n",
        "                      'river flood', 'urban flood', 'small stream flood']\n",
        "    \n",
        "    # Invert the mask with ~ to select rows that DON'T contain flooding keywords\n",
        "    mask = ~df['EVENT_TYPE'].str.lower().str.contains('|'.join(flood_keywords), \n",
        "                                                       case=False, \n",
        "                                                       na=False)    \n",
        "    if state is not None:\n",
        "        if 'STATE' not in df.columns:\n",
        "            print(f\"Warning: STATE column not found, cannot filter by state\")\n",
        "        else:\n",
        "            state_mask = df['STATE'].str.upper() == state.upper()\n",
        "            mask = mask & state_mask\n",
        "    \n",
        "    df = df[mask].copy()\n",
        "\n",
        "    # Remove rows with invalid coordinates\n",
        "    if 'BEGIN_LAT' in df.columns and 'BEGIN_LON' in df.columns:\n",
        "        df['BEGIN_LAT'] = pd.to_numeric(df['BEGIN_LAT'], errors='coerce')\n",
        "        df['BEGIN_LON'] = pd.to_numeric(df['BEGIN_LON'], errors='coerce')\n",
        "        mask = (df['BEGIN_LAT'].notna()) & (df['BEGIN_LON'].notna()) & \\\n",
        "            (df['BEGIN_LAT'] != 0) & (df['BEGIN_LON'] != 0)\n",
        "        \n",
        "        filtered_df = df[mask].copy()\n",
        "    else:\n",
        "        filtered_df = df.copy()\n",
        "\n",
        "    return filtered_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_yearmonth(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    if df.empty or 'BEGIN_YEARMONTH' not in df.columns:\n",
        "        return df\n",
        "    \n",
        "    df = df.copy()\n",
        "    df['YEAR'] = df['BEGIN_YEARMONTH'].astype(str).str[:4].astype(int)\n",
        "    df['MONTH'] = df['BEGIN_YEARMONTH'].astype(str).str[4:6].astype(int)\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    columns_to_keep = [\n",
        "        'YEAR',\n",
        "        'MONTH',\n",
        "        'BEGIN_DAY',\n",
        "        'BEGIN_TIME',\n",
        "        'BEGIN_LAT',\n",
        "        'BEGIN_LON',\n",
        "        'STATE',\n",
        "        'EVENT_TYPE',\n",
        "        'FLOOD_CAUSE',\n",
        "        'EVENT_NARRATIVE'\n",
        "    ]\n",
        "    \n",
        "\n",
        "    available_columns = [col for col in columns_to_keep if col in df.columns]\n",
        "    missing_columns = [col for col in columns_to_keep if col not in df.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Warning: The following columns were not found: {missing_columns}\")\n",
        "    \n",
        "    if not available_columns:\n",
        "        print(\"Warning: None of the requested columns were found in the DataFrame\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    selected_df = df[available_columns].copy()\n",
        "    return selected_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_all_csv_files(raw_data_dir: str, state: str = None) -> pd.DataFrame:\n",
        "    csv_files = get_csv_files(raw_data_dir)\n",
        "    \n",
        "    if not csv_files:\n",
        "        print(f\"No CSV files found in {raw_data_dir}\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    print(f\"Found {len(csv_files)} CSV file(s) to process\")\n",
        "    if state:\n",
        "        print(f\"Filtering for state: {state.upper()}\")\n",
        "    \n",
        "    all_flooding_events = []\n",
        "    \n",
        "    for csv_file in csv_files:\n",
        "        print(f\"Processing {os.path.basename(csv_file)}...\")\n",
        "        df = parse_csv_file(csv_file)\n",
        "        \n",
        "        if not df.empty:\n",
        "            flooding_df = filter_flooding_events(df, state=state)\n",
        "            if not flooding_df.empty:\n",
        "                print(f\"  Found {len(flooding_df)} flooding event(s)\")\n",
        "                all_flooding_events.append(flooding_df)\n",
        "            else:\n",
        "                print(f\"  No flooding events found\")\n",
        "        else:\n",
        "            print(f\"  Failed to parse or file is empty\")\n",
        "    \n",
        "    if all_flooding_events:\n",
        "        combined_df = pd.concat(all_flooding_events, ignore_index=True)\n",
        "        print(f\"\\nTotal flooding events found: {len(combined_df)}\")\n",
        "        \n",
        "        combined_df = split_yearmonth(combined_df)\n",
        "        selected_df = select_columns(combined_df)\n",
        "        return selected_df\n",
        "    else:\n",
        "        print(\"\\nNo flooding events found in any files\")\n",
        "        return pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data directory: raw_data\n",
            "State filter: TEXAS\n"
          ]
        }
      ],
      "source": [
        "raw_data_dir = \"raw_data\"\n",
        "state_filter = \"TEXAS\" \n",
        "\n",
        "print(f\"Data directory: {raw_data_dir}\")\n",
        "print(f\"State filter: {state_filter if state_filter else 'None (all states)'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25 CSV file(s) to process\n",
            "Filtering for state: TEXAS\n",
            "Processing StormEvents_details-ftp_v1.0_d2001_c20250520.csv...\n",
            "  Found 2133 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2002_c20250520.csv...\n",
            "  Found 2592 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2003_c20250520.csv...\n",
            "  Found 2311 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2004_c20250520.csv...\n",
            "  Found 2516 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2005_c20250520.csv...\n",
            "  Found 2355 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2006_c20250520.csv...\n",
            "  Found 1932 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2007_c20250520.csv...\n",
            "  Found 2499 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2008_c20250520.csv...\n",
            "  Found 2492 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2009_c20250520.csv...\n",
            "  Found 3002 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2010_c20250520.csv...\n",
            "  Found 1727 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2011_c20250520.csv...\n",
            "  Found 2292 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2012_c20250520.csv...\n",
            "  Found 2607 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2013_c20250520.csv...\n",
            "  Found 2130 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2014_c20250520.csv...\n",
            "  Found 1995 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2015_c20250818.csv...\n",
            "  Found 2577 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2016_c20250818.csv...\n",
            "  Found 2341 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2017_c20250520.csv...\n",
            "  Found 2459 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2018_c20250520.csv...\n",
            "  Found 1701 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2019_c20250520.csv...\n",
            "  Found 2673 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2020_c20250702.csv...\n",
            "  Found 2044 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2021_c20250520.csv...\n",
            "  Found 2042 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2022_c20250721.csv...\n",
            "  Found 1731 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2023_c20250731.csv...\n",
            "  Found 3305 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2024_c20250818.csv...\n",
            "  Found 2763 flooding event(s)\n",
            "Processing StormEvents_details-ftp_v1.0_d2025_c20250818.csv...\n",
            "  Found 1741 flooding event(s)\n",
            "\n",
            "Total flooding events found: 57960\n"
          ]
        }
      ],
      "source": [
        "non_flooding_events_df = process_all_csv_files(str(raw_data_dir), state=state_filter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total rows: 57960\n",
            "\n",
            "Columns: ['YEAR', 'MONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'BEGIN_LAT', 'BEGIN_LON', 'STATE', 'EVENT_TYPE', 'FLOOD_CAUSE', 'EVENT_NARRATIVE']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>BEGIN_DAY</th>\n",
              "      <th>BEGIN_TIME</th>\n",
              "      <th>BEGIN_LAT</th>\n",
              "      <th>BEGIN_LON</th>\n",
              "      <th>STATE</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>FLOOD_CAUSE</th>\n",
              "      <th>EVENT_NARRATIVE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>1555</td>\n",
              "      <td>30.93333</td>\n",
              "      <td>-97.53333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There was wind damage to two recreational vehi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>1530</td>\n",
              "      <td>32.65000</td>\n",
              "      <td>-98.90000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Hail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>2050</td>\n",
              "      <td>33.51667</td>\n",
              "      <td>-96.18333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The roof of a barn was blown off by high winds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>2155</td>\n",
              "      <td>30.68333</td>\n",
              "      <td>-94.18333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>2215</td>\n",
              "      <td>30.65000</td>\n",
              "      <td>-93.91667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2001</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>2220</td>\n",
              "      <td>30.68333</td>\n",
              "      <td>-93.81667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2001</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>518</td>\n",
              "      <td>30.91667</td>\n",
              "      <td>-94.00000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2001</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>545</td>\n",
              "      <td>30.35000</td>\n",
              "      <td>-94.06667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2001</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>603</td>\n",
              "      <td>31.00000</td>\n",
              "      <td>-93.63333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2001</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1110</td>\n",
              "      <td>30.05000</td>\n",
              "      <td>-94.88333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Hail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Liberty Sheriff reported 3/4 inch hail near Da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  BEGIN_DAY  BEGIN_TIME  BEGIN_LAT  BEGIN_LON  STATE  \\\n",
              "0  2001     11         15        1555   30.93333  -97.53333  TEXAS   \n",
              "1  2001     11         11        1530   32.65000  -98.90000  TEXAS   \n",
              "2  2001     11         23        2050   33.51667  -96.18333  TEXAS   \n",
              "3  2001     12         16        2155   30.68333  -94.18333  TEXAS   \n",
              "4  2001     12         16        2215   30.65000  -93.91667  TEXAS   \n",
              "5  2001     12         16        2220   30.68333  -93.81667  TEXAS   \n",
              "6  2001      1         29         518   30.91667  -94.00000  TEXAS   \n",
              "7  2001      1         29         545   30.35000  -94.06667  TEXAS   \n",
              "8  2001      1         29         603   31.00000  -93.63333  TEXAS   \n",
              "9  2001     12         13        1110   30.05000  -94.88333  TEXAS   \n",
              "\n",
              "          EVENT_TYPE FLOOD_CAUSE  \\\n",
              "0  Thunderstorm Wind         NaN   \n",
              "1               Hail         NaN   \n",
              "2  Thunderstorm Wind         NaN   \n",
              "3  Thunderstorm Wind         NaN   \n",
              "4  Thunderstorm Wind         NaN   \n",
              "5  Thunderstorm Wind         NaN   \n",
              "6  Thunderstorm Wind         NaN   \n",
              "7  Thunderstorm Wind         NaN   \n",
              "8  Thunderstorm Wind         NaN   \n",
              "9               Hail         NaN   \n",
              "\n",
              "                                     EVENT_NARRATIVE  \n",
              "0  There was wind damage to two recreational vehi...  \n",
              "1                                                NaN  \n",
              "2    The roof of a barn was blown off by high winds.  \n",
              "3                                                NaN  \n",
              "4                                                NaN  \n",
              "5                                                NaN  \n",
              "6                                                NaN  \n",
              "7                                                NaN  \n",
              "8                                                NaN  \n",
              "9  Liberty Sheriff reported 3/4 inch hail near Da...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57960 entries, 0 to 57959\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   YEAR             57960 non-null  int64  \n",
            " 1   MONTH            57960 non-null  int64  \n",
            " 2   BEGIN_DAY        57960 non-null  int64  \n",
            " 3   BEGIN_TIME       57960 non-null  int64  \n",
            " 4   BEGIN_LAT        57960 non-null  float64\n",
            " 5   BEGIN_LON        57960 non-null  float64\n",
            " 6   STATE            57960 non-null  object \n",
            " 7   EVENT_TYPE       57960 non-null  object \n",
            " 8   FLOOD_CAUSE      1 non-null      object \n",
            " 9   EVENT_NARRATIVE  40373 non-null  object \n",
            "dtypes: float64(2), int64(4), object(4)\n",
            "memory usage: 4.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Display summary information\n",
        "if not non_flooding_events_df.empty:\n",
        "    print(f\"\\nTotal rows: {len(non_flooding_events_df)}\")\n",
        "    print(f\"\\nColumns: {list(non_flooding_events_df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(non_flooding_events_df.head(10))\n",
        "    \n",
        "    print(f\"\\nDataFrame info:\")\n",
        "    non_flooding_events_df.info()\n",
        "else:\n",
        "    print(\"No flooding events found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>BEGIN_DAY</th>\n",
              "      <th>BEGIN_TIME</th>\n",
              "      <th>BEGIN_LAT</th>\n",
              "      <th>BEGIN_LON</th>\n",
              "      <th>STATE</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>FLOOD_CAUSE</th>\n",
              "      <th>EVENT_NARRATIVE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44591</th>\n",
              "      <td>2020</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1530</td>\n",
              "      <td>30.67000</td>\n",
              "      <td>-95.53000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Hail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Softball sized hail was reported.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20409</th>\n",
              "      <td>2009</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1512</td>\n",
              "      <td>33.25960</td>\n",
              "      <td>-99.90000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Tornado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A trained spotter reported a brief tornado tou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10693</th>\n",
              "      <td>2005</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>28.68333</td>\n",
              "      <td>-99.81667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Severe thunderstorms struck Crystal City, knoc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56753</th>\n",
              "      <td>2025</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>2053</td>\n",
              "      <td>33.18000</td>\n",
              "      <td>-96.50000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Hail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amateur radio operator reported half dollar si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19761</th>\n",
              "      <td>2009</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>1742</td>\n",
              "      <td>33.80900</td>\n",
              "      <td>-97.73000</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Hail</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Half dollar size hail fell 2 miles north of No...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR  MONTH  BEGIN_DAY  BEGIN_TIME  BEGIN_LAT  BEGIN_LON  STATE  \\\n",
              "44591  2020      4         18        1530   30.67000  -95.53000  TEXAS   \n",
              "20409  2009      5          1        1512   33.25960  -99.90000  TEXAS   \n",
              "10693  2005      6          4        2020   28.68333  -99.81667  TEXAS   \n",
              "56753  2025      3         25        2053   33.18000  -96.50000  TEXAS   \n",
              "19761  2009      3         26        1742   33.80900  -97.73000  TEXAS   \n",
              "\n",
              "              EVENT_TYPE FLOOD_CAUSE  \\\n",
              "44591               Hail         NaN   \n",
              "20409            Tornado         NaN   \n",
              "10693  Thunderstorm Wind         NaN   \n",
              "56753               Hail         NaN   \n",
              "19761               Hail         NaN   \n",
              "\n",
              "                                         EVENT_NARRATIVE  \n",
              "44591                  Softball sized hail was reported.  \n",
              "20409  A trained spotter reported a brief tornado tou...  \n",
              "10693  Severe thunderstorms struck Crystal City, knoc...  \n",
              "56753  Amateur radio operator reported half dollar si...  \n",
              "19761  Half dollar size hail fell 2 miles north of No...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get a random subset of 10000 rows from the non_flooding_events_df\n",
        "non_flooding_events_df = non_flooding_events_df.sample(n=9500)\n",
        "non_flooding_events_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openmeteo-requests in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (1.7.4)\n",
            "Requirement already satisfied: niquests>=3.15.2 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from openmeteo-requests) (3.15.2)\n",
            "Requirement already satisfied: openmeteo-sdk>=1.22.0 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from openmeteo-requests) (1.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from niquests>=3.15.2->openmeteo-requests) (3.4.4)\n",
            "Requirement already satisfied: urllib3-future<3,>=2.13.903 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from niquests>=3.15.2->openmeteo-requests) (2.14.907)\n",
            "Requirement already satisfied: wassima<3,>=1.0.1 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from niquests>=3.15.2->openmeteo-requests) (2.0.2)\n",
            "Requirement already satisfied: h11<1.0.0,>=0.11.0 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (0.16.0)\n",
            "Requirement already satisfied: jh2<6.0.0,>=5.0.3 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (5.0.10)\n",
            "Requirement already satisfied: qh3<2.0.0,>=1.5.4 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from urllib3-future<3,>=2.13.903->niquests>=3.15.2->openmeteo-requests) (1.5.6)\n",
            "Requirement already satisfied: flatbuffers==25.9.23 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from openmeteo-sdk>=1.22.0->openmeteo-requests) (25.9.23)\n",
            "Requirement already satisfied: requests-cache in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (1.2.1)\n",
            "Requirement already satisfied: retry-requests in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (2.0.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (25.4.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (25.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.22 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (2.32.5)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (2.2.1)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests-cache) (2.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ananthkothuri/VSCode/GeospatialAIProject/.venv/lib/python3.10/site-packages (from requests>=2.22->requests-cache) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install openmeteo-requests\n",
        "!pip3 install requests-cache retry-requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augmenting flooding data using the [Open Meteo API](https://open-meteo.com/en/docs/climate-api?utm_source=chatgpt.com&daily=temperature_2m_mean,wind_speed_10m_mean,cloud_cover_mean,relative_humidity_2m_mean,dew_point_2m_mean,precipitation_sum,rain_sum,snowfall_sum,pressure_msl_mean,soil_moisture_0_to_10cm_mean&start_date=2020-01-01&end_date=2020-01-01&models=EC_Earth3P_HR#settings)\n",
        "\n",
        "This is an open-sourced api that allows you to entire a lat, long, and date and it gives you data on the weather conditions of that area at the time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "from retry_requests import retry\n",
        "\n",
        "def get_weather_data(lat: float, lon: float, date: str) -> dict:\n",
        "    cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
        "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "    url = \"https://climate-api.open-meteo.com/v1/climate\"\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"start_date\": date,\n",
        "        \"end_date\": date,\n",
        "        \"models\": \"EC_Earth3P_HR\",\n",
        "        \"daily\": [\"temperature_2m_mean\", \"wind_speed_10m_mean\", \"cloud_cover_mean\", \"relative_humidity_2m_mean\", \"dew_point_2m_mean\", \"precipitation_sum\", \"rain_sum\", \"snowfall_sum\", \"pressure_msl_mean\", \"soil_moisture_0_to_10cm_mean\"],\n",
        "        \"utm_source\": \"chatgpt.com\",\n",
        "    }\n",
        "    responses = openmeteo.weather_api(url, params=params)\n",
        "    response = responses[0]\n",
        "\n",
        "    daily = response.Daily()\n",
        "    daily_temperature_2m_mean = daily.Variables(0).ValuesAsNumpy()\n",
        "    daily_wind_speed_10m_mean = daily.Variables(1).ValuesAsNumpy()\n",
        "    daily_cloud_cover_mean = daily.Variables(2).ValuesAsNumpy()\n",
        "    daily_relative_humidity_2m_mean = daily.Variables(3).ValuesAsNumpy()\n",
        "    daily_dew_point_2m_mean = daily.Variables(4).ValuesAsNumpy()\n",
        "    daily_precipitation_sum = daily.Variables(5).ValuesAsNumpy()\n",
        "    daily_rain_sum = daily.Variables(6).ValuesAsNumpy()\n",
        "    daily_snowfall_sum = daily.Variables(7).ValuesAsNumpy()\n",
        "    daily_pressure_msl_mean = daily.Variables(8).ValuesAsNumpy()\n",
        "    daily_soil_moisture_0_to_10cm_mean = daily.Variables(9).ValuesAsNumpy()\n",
        "\n",
        "    daily_data = {\"date\": date}\n",
        "\n",
        "    daily_data[\"temperature_2m_mean\"] = daily_temperature_2m_mean\n",
        "    daily_data[\"wind_speed_10m_mean\"] = daily_wind_speed_10m_mean\n",
        "    daily_data[\"cloud_cover_mean\"] = daily_cloud_cover_mean\n",
        "    daily_data[\"relative_humidity_2m_mean\"] = daily_relative_humidity_2m_mean\n",
        "    daily_data[\"dew_point_2m_mean\"] = daily_dew_point_2m_mean\n",
        "    daily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
        "    daily_data[\"rain_sum\"] = daily_rain_sum\n",
        "    daily_data[\"snowfall_sum\"] = daily_snowfall_sum\n",
        "    daily_data[\"pressure_msl_mean\"] = daily_pressure_msl_mean\n",
        "    daily_data[\"soil_moisture_0_to_10cm_mean\"] = daily_soil_moisture_0_to_10cm_mean\n",
        "    daily_data[\"elevation\"] = response.Elevation()\n",
        "\n",
        "    daily_dataframe = pd.DataFrame(data = daily_data)\n",
        "    return daily_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmenting 9340 flooding events with weather data...\n",
            "This may take a while due to API rate limits...\n",
            "\n",
            "Processed 50/9340 events...\n",
            "Processed 100/9340 events...\n",
            "Processed 150/9340 events...\n",
            "Processed 200/9340 events...\n",
            "Processed 250/9340 events...\n",
            "Processed 300/9340 events...\n",
            "Processed 350/9340 events...\n",
            "Processed 400/9340 events...\n",
            "Processed 450/9340 events...\n",
            "Processed 500/9340 events...\n",
            "Processed 550/9340 events...\n",
            "Processed 600/9340 events...\n",
            "Processed 650/9340 events...\n",
            "Processed 700/9340 events...\n",
            "Processed 750/9340 events...\n",
            "Processed 800/9340 events...\n",
            "Processed 850/9340 events...\n",
            "Processed 900/9340 events...\n",
            "Processed 950/9340 events...\n",
            "Processed 1000/9340 events...\n",
            "Processed 1050/9340 events...\n",
            "Processed 1100/9340 events...\n",
            "Processed 1150/9340 events...\n",
            "Processed 1200/9340 events...\n",
            "Processed 1250/9340 events...\n",
            "Processed 1300/9340 events...\n",
            "Processed 1350/9340 events...\n",
            "Processed 1400/9340 events...\n",
            "Processed 1450/9340 events...\n",
            "Processed 1500/9340 events...\n",
            "Processed 1550/9340 events...\n",
            "Processed 1600/9340 events...\n",
            "Processed 1650/9340 events...\n",
            "Processed 1700/9340 events...\n",
            "Processed 1750/9340 events...\n",
            "Processed 1800/9340 events...\n",
            "Processed 1850/9340 events...\n",
            "Processed 1900/9340 events...\n",
            "Processed 1950/9340 events...\n",
            "Processed 2000/9340 events...\n",
            "Processed 2050/9340 events...\n",
            "Processed 2100/9340 events...\n",
            "Processed 2150/9340 events...\n",
            "Processed 2200/9340 events...\n",
            "Processed 2250/9340 events...\n",
            "Processed 2300/9340 events...\n",
            "Processed 2350/9340 events...\n",
            "Processed 2400/9340 events...\n",
            "Processed 2450/9340 events...\n",
            "Processed 2500/9340 events...\n",
            "Processed 2550/9340 events...\n",
            "Processed 2600/9340 events...\n",
            "Processed 2650/9340 events...\n",
            "Processed 2700/9340 events...\n",
            "Processed 2750/9340 events...\n",
            "Processed 2800/9340 events...\n",
            "Processed 2850/9340 events...\n",
            "Processed 2900/9340 events...\n",
            "Processed 2950/9340 events...\n",
            "Processed 3000/9340 events...\n",
            "Processed 3050/9340 events...\n",
            "Processed 3100/9340 events...\n",
            "Processed 3150/9340 events...\n",
            "Processed 3200/9340 events...\n",
            "Processed 3250/9340 events...\n",
            "Processed 3300/9340 events...\n",
            "Processed 3350/9340 events...\n",
            "Processed 3400/9340 events...\n",
            "Processed 3450/9340 events...\n",
            "Processed 3500/9340 events...\n",
            "Processed 3550/9340 events...\n",
            "Processed 3600/9340 events...\n",
            "Processed 3650/9340 events...\n",
            "Processed 3700/9340 events...\n",
            "Processed 3750/9340 events...\n",
            "Processed 3800/9340 events...\n",
            "Processed 3850/9340 events...\n",
            "Processed 3900/9340 events...\n",
            "Processed 3950/9340 events...\n",
            "Processed 4000/9340 events...\n",
            "Processed 4050/9340 events...\n",
            "Processed 4100/9340 events...\n",
            "Processed 4150/9340 events...\n",
            "Processed 4200/9340 events...\n",
            "Processed 4250/9340 events...\n",
            "Processed 4300/9340 events...\n",
            "Processed 4350/9340 events...\n",
            "Processed 4400/9340 events...\n",
            "Processed 4450/9340 events...\n",
            "Processed 4500/9340 events...\n",
            "Processed 4550/9340 events...\n",
            "Processed 4600/9340 events...\n",
            "Processed 4650/9340 events...\n",
            "Processed 4700/9340 events...\n",
            "Processed 4750/9340 events...\n",
            "Processed 4800/9340 events...\n",
            "Processed 4850/9340 events...\n",
            "Processed 4900/9340 events...\n",
            "Processed 4950/9340 events...\n",
            "Processed 5000/9340 events...\n",
            "Processed 5050/9340 events...\n",
            "Processed 5100/9340 events...\n",
            "Processed 5150/9340 events...\n",
            "Processed 5200/9340 events...\n",
            "Processed 5250/9340 events...\n",
            "Processed 5300/9340 events...\n",
            "Processed 5350/9340 events...\n",
            "Processed 5400/9340 events...\n",
            "Processed 5450/9340 events...\n",
            "Processed 5500/9340 events...\n",
            "Processed 5550/9340 events...\n",
            "Processed 5600/9340 events...\n",
            "Processed 5650/9340 events...\n",
            "Processed 5700/9340 events...\n",
            "Processed 5750/9340 events...\n",
            "Processed 5800/9340 events...\n",
            "Processed 5850/9340 events...\n",
            "Processed 5900/9340 events...\n",
            "Processed 5950/9340 events...\n",
            "Processed 6000/9340 events...\n",
            "Processed 6050/9340 events...\n",
            "Processed 6100/9340 events...\n",
            "Processed 6150/9340 events...\n",
            "Processed 6200/9340 events...\n",
            "Processed 6250/9340 events...\n",
            "Processed 6300/9340 events...\n",
            "Processed 6350/9340 events...\n",
            "Processed 6400/9340 events...\n",
            "Processed 6450/9340 events...\n",
            "Processed 6500/9340 events...\n",
            "Processed 6550/9340 events...\n",
            "Processed 6600/9340 events...\n",
            "Processed 6650/9340 events...\n",
            "Processed 6700/9340 events...\n",
            "Processed 6750/9340 events...\n",
            "Processed 6800/9340 events...\n",
            "Processed 6850/9340 events...\n",
            "Processed 6900/9340 events...\n",
            "Processed 6950/9340 events...\n",
            "Processed 7000/9340 events...\n",
            "Processed 7050/9340 events...\n",
            "Processed 7100/9340 events...\n",
            "Processed 7150/9340 events...\n",
            "Processed 7200/9340 events...\n",
            "Processed 7250/9340 events...\n",
            "Processed 7300/9340 events...\n",
            "Processed 7350/9340 events...\n",
            "Processed 7400/9340 events...\n",
            "Processed 7450/9340 events...\n",
            "Processed 7500/9340 events...\n",
            "Processed 7550/9340 events...\n",
            "Processed 7600/9340 events...\n",
            "Processed 7650/9340 events...\n",
            "Processed 7700/9340 events...\n",
            "Processed 7750/9340 events...\n",
            "Processed 7800/9340 events...\n",
            "Processed 7850/9340 events...\n",
            "Processed 7900/9340 events...\n",
            "Processed 7950/9340 events...\n",
            "Processed 8000/9340 events...\n",
            "Processed 8050/9340 events...\n",
            "Processed 8100/9340 events...\n",
            "Processed 8150/9340 events...\n",
            "Processed 8200/9340 events...\n",
            "Processed 8250/9340 events...\n",
            "Processed 8300/9340 events...\n",
            "Processed 8350/9340 events...\n",
            "Processed 8400/9340 events...\n",
            "Processed 8450/9340 events...\n",
            "Processed 8500/9340 events...\n",
            "Processed 8550/9340 events...\n",
            "Processed 8600/9340 events...\n",
            "Processed 8650/9340 events...\n",
            "Processed 8700/9340 events...\n",
            "Processed 8750/9340 events...\n",
            "Processed 8800/9340 events...\n",
            "Processed 8850/9340 events...\n",
            "Processed 8900/9340 events...\n",
            "Processed 8950/9340 events...\n",
            "Processed 9000/9340 events...\n",
            "Processed 9050/9340 events...\n",
            "Processed 9100/9340 events...\n",
            "Processed 9150/9340 events...\n",
            "Processed 9200/9340 events...\n",
            "Processed 9250/9340 events...\n",
            "Processed 9300/9340 events...\n",
            "\n",
            "Augmentation complete! Processed 9340 events.\n",
            "\n",
            "Augmented DataFrame shape: (9340, 21)\n",
            "\n",
            "New columns added: {'cloud_cover_mean', 'temperature_2m_mean', 'rain_sum', 'soil_moisture_0_to_10cm_mean', 'snowfall_sum', 'elevation', 'pressure_msl_mean', 'dew_point_2m_mean', 'relative_humidity_2m_mean', 'precipitation_sum', 'wind_speed_10m_mean'}\n",
            "\n",
            "First few rows of augmented data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>BEGIN_DAY</th>\n",
              "      <th>BEGIN_TIME</th>\n",
              "      <th>BEGIN_LAT</th>\n",
              "      <th>BEGIN_LON</th>\n",
              "      <th>STATE</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>FLOOD_CAUSE</th>\n",
              "      <th>EVENT_NARRATIVE</th>\n",
              "      <th>...</th>\n",
              "      <th>wind_speed_10m_mean</th>\n",
              "      <th>cloud_cover_mean</th>\n",
              "      <th>relative_humidity_2m_mean</th>\n",
              "      <th>dew_point_2m_mean</th>\n",
              "      <th>precipitation_sum</th>\n",
              "      <th>rain_sum</th>\n",
              "      <th>snowfall_sum</th>\n",
              "      <th>pressure_msl_mean</th>\n",
              "      <th>soil_moisture_0_to_10cm_mean</th>\n",
              "      <th>elevation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>140</td>\n",
              "      <td>32.53333</td>\n",
              "      <td>-96.66667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Flash Flood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Roads were closed near Sanger due to high water.</td>\n",
              "      <td>...</td>\n",
              "      <td>21.042433</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.388832</td>\n",
              "      <td>4.528868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1001.218079</td>\n",
              "      <td>0.432614</td>\n",
              "      <td>146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>33.73333</td>\n",
              "      <td>-102.78333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Flash Flood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I-27 was flooded and subsequently closed due t...</td>\n",
              "      <td>...</td>\n",
              "      <td>22.688942</td>\n",
              "      <td>3.063162</td>\n",
              "      <td>45.882435</td>\n",
              "      <td>12.775488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1007.632996</td>\n",
              "      <td>0.110644</td>\n",
              "      <td>1150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>125</td>\n",
              "      <td>31.46667</td>\n",
              "      <td>-97.71667</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Flash Flood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Water was over Northwest Highway at Hillcrest ...</td>\n",
              "      <td>...</td>\n",
              "      <td>13.942765</td>\n",
              "      <td>44.521587</td>\n",
              "      <td>68.509903</td>\n",
              "      <td>18.607435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.453674</td>\n",
              "      <td>0.302950</td>\n",
              "      <td>265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>128</td>\n",
              "      <td>33.08333</td>\n",
              "      <td>-97.13333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Flash Flood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Water was over Highway 75 at Parkview.</td>\n",
              "      <td>...</td>\n",
              "      <td>12.174953</td>\n",
              "      <td>53.005688</td>\n",
              "      <td>65.300453</td>\n",
              "      <td>18.778494</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.608337</td>\n",
              "      <td>0.192466</td>\n",
              "      <td>190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1700</td>\n",
              "      <td>33.36667</td>\n",
              "      <td>-97.68333</td>\n",
              "      <td>TEXAS</td>\n",
              "      <td>Flash Flood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Flooding resulted in high water rescues and ma...</td>\n",
              "      <td>...</td>\n",
              "      <td>9.831195</td>\n",
              "      <td>54.140934</td>\n",
              "      <td>63.182789</td>\n",
              "      <td>18.967064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.293640</td>\n",
              "      <td>0.186347</td>\n",
              "      <td>280.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  BEGIN_DAY  BEGIN_TIME  BEGIN_LAT  BEGIN_LON  STATE  \\\n",
              "0  2001      3         11         140   32.53333  -96.66667  TEXAS   \n",
              "1  2001      5          4          15   33.73333 -102.78333  TEXAS   \n",
              "2  2001      5          6         125   31.46667  -97.71667  TEXAS   \n",
              "3  2001      5          6         128   33.08333  -97.13333  TEXAS   \n",
              "4  2001      5          6        1700   33.36667  -97.68333  TEXAS   \n",
              "\n",
              "    EVENT_TYPE FLOOD_CAUSE                                    EVENT_NARRATIVE  \\\n",
              "0  Flash Flood         NaN   Roads were closed near Sanger due to high water.   \n",
              "1  Flash Flood         NaN  I-27 was flooded and subsequently closed due t...   \n",
              "2  Flash Flood         NaN  Water was over Northwest Highway at Hillcrest ...   \n",
              "3  Flash Flood         NaN             Water was over Highway 75 at Parkview.   \n",
              "4  Flash Flood         NaN  Flooding resulted in high water rescues and ma...   \n",
              "\n",
              "   ...  wind_speed_10m_mean  cloud_cover_mean  relative_humidity_2m_mean  \\\n",
              "0  ...            21.042433          0.000000                  39.388832   \n",
              "1  ...            22.688942          3.063162                  45.882435   \n",
              "2  ...            13.942765         44.521587                  68.509903   \n",
              "3  ...            12.174953         53.005688                  65.300453   \n",
              "4  ...             9.831195         54.140934                  63.182789   \n",
              "\n",
              "   dew_point_2m_mean  precipitation_sum  rain_sum  snowfall_sum  \\\n",
              "0           4.528868                0.0       0.0           0.0   \n",
              "1          12.775488                0.0       0.0           0.0   \n",
              "2          18.607435                0.0       0.0           0.0   \n",
              "3          18.778494                0.0       0.0           0.0   \n",
              "4          18.967064                0.0       0.0           0.0   \n",
              "\n",
              "   pressure_msl_mean  soil_moisture_0_to_10cm_mean  elevation  \n",
              "0        1001.218079                      0.432614      146.0  \n",
              "1        1007.632996                      0.110644     1150.0  \n",
              "2        1016.453674                      0.302950      265.0  \n",
              "3        1016.608337                      0.192466      190.0  \n",
              "4        1016.293640                      0.186347      280.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Augmented data saved to: flooding_events_augmented.csv\n"
          ]
        }
      ],
      "source": [
        "# For every flooding event, augment the row with the weather data\n",
        "# Add the weather data to the flooding data\n",
        "# Save the augmented data to a new csv file\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def augment_flooding_data_with_weather(flooding_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    augmented_rows = []\n",
        "    total_rows = len(flooding_df)\n",
        "    \n",
        "    print(f\"Augmenting {total_rows} flooding events with weather data...\")\n",
        "    print(\"This may take a while due to API rate limits...\\n\")\n",
        "    \n",
        "    for idx, row in flooding_df.iterrows():\n",
        "        try:\n",
        "            year = int(row['YEAR'])\n",
        "            month = int(row['MONTH'])\n",
        "            day = int(row['BEGIN_DAY'])\n",
        "            date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
        "            \n",
        "            weather_df = get_weather_data(\n",
        "                lat=float(row['BEGIN_LAT']),\n",
        "                lon=float(row['BEGIN_LON']),\n",
        "                date=date_str\n",
        "            )\n",
        "            \n",
        "            if not weather_df.empty:\n",
        "                weather_row = weather_df.iloc[0]\n",
        "                augmented_row = row.to_dict()\n",
        "                \n",
        "                for col in weather_df.columns:\n",
        "                    if col != 'date':\n",
        "                        augmented_row[col] = weather_row[col]\n",
        "                augmented_rows.append(augmented_row)\n",
        "            else:\n",
        "                augmented_rows.append(row.to_dict())\n",
        "            \n",
        "            if (idx + 1) % 50 == 0:\n",
        "                print(f\"Processed {idx + 1}/{total_rows} events...\")\n",
        "            time.sleep(0.1)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {idx}: {e}\")\n",
        "            augmented_rows.append(row.to_dict())\n",
        "    augmented_df = pd.DataFrame(augmented_rows)\n",
        "    \n",
        "    print(f\"\\nAugmentation complete! Processed {len(augmented_df)} events.\")\n",
        "    return augmented_df\n",
        "\n",
        "# Augment the flooding events with weather data\n",
        "augmented_non_flooding_df = augment_flooding_data_with_weather(non_flooding_events_df)\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\nAugmented DataFrame shape: {augmented_non_flooding_df.shape}\")\n",
        "print(f\"\\nNew columns added: {set(augmented_non_flooding_df.columns) - set(augmented_non_flooding_df.columns)}\")\n",
        "print(f\"\\nFirst few rows of augmented data:\")\n",
        "display(augmented_non_flooding_df.head())\n",
        "\n",
        "# Save to CSV file\n",
        "output_path = \"non_flooding_events_augmented.csv\"\n",
        "augmented_non_flooding_df.to_csv(output_path, index=False)\n",
        "print(f\"\\nAugmented data saved to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
